{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1. 自定义损失函数.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"-LkGbAgpKrgK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import tensorflow as tf\n","from numpy.random import RandomState"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GIc-7A-uKrgO","colab_type":"text"},"cell_type":"markdown","source":["#### 1. 定义神经网络的相关参数和变量。"]},{"metadata":{"id":"XShGX5dWKrgP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["batch_size = 8\n","x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")\n","y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y-input')\n","w1= tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))\n","y = tf.matmul(x, w1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jT59MOvtKrgS","colab_type":"text"},"cell_type":"markdown","source":["#### 2. 设置自定义的损失函数。"]},{"metadata":{"id":"ponEDM4qKrgU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 定义损失函数使得预测少了的损失大，于是模型应该偏向多的方向预测。\n","loss_less = 10\n","loss_more = 1\n","loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * loss_more, (y_ - y) * loss_less))\n","train_step = tf.train.AdamOptimizer(0.001).minimize(loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eZjalpInKrgX","colab_type":"text"},"cell_type":"markdown","source":["#### 3. 生成模拟数据集。"]},{"metadata":{"id":"7xxWRwsNKrgX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["rdm = RandomState(1)\n","X = rdm.rand(128,2)\n","Y = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1, x2) in X]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nXxduFtoKrga","colab_type":"text"},"cell_type":"markdown","source":["#### 4. 训练模型。"]},{"metadata":{"id":"fGSPDx-FKrgb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"1e482370-c809-4eb9-d5af-7b915f096104"},"cell_type":"code","source":["with tf.Session() as sess:\n","    init_op = tf.global_variables_initializer()\n","    sess.run(init_op)\n","    STEPS = 5000\n","    for i in range(STEPS):\n","        start = (i*batch_size) % 128\n","        end = (i*batch_size) % 128 + batch_size\n","        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n","        if i % 1000 == 0:\n","            print(\"After %d training step(s), w1 is: \" % (i))\n","            print sess.run(w1), \"\\n\"\n","    print \"Final w1 is: \\n\", sess.run(w1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["After 0 training step(s), w1 is: \n","[[-0.81031823]\n"," [ 1.4855988 ]] \n","\n","After 1000 training step(s), w1 is: \n","[[ 0.01247112]\n"," [ 2.1385448 ]] \n","\n","After 2000 training step(s), w1 is: \n","[[ 0.45567414]\n"," [ 2.17060661]] \n","\n","After 3000 training step(s), w1 is: \n","[[ 0.69968724]\n"," [ 1.8465308 ]] \n","\n","After 4000 training step(s), w1 is: \n","[[ 0.89886665]\n"," [ 1.29736018]] \n","\n","Final w1 is: \n","[[ 1.01934695]\n"," [ 1.04280889]]\n"],"name":"stdout"}]},{"metadata":{"id":"SJoin8NsKrgi","colab_type":"text"},"cell_type":"markdown","source":["#### 5. 重新定义损失函数，使得预测多了的损失大，于是模型应该偏向少的方向预测。"]},{"metadata":{"id":"_anykcLEKrgi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"0584862b-8e52-4e07-a8f4-fdcc16092915"},"cell_type":"code","source":["loss_less = 1\n","loss_more = 10\n","loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * loss_more, (y_ - y) * loss_less))\n","train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n","\n","with tf.Session() as sess:\n","    init_op = tf.global_variables_initializer()\n","    sess.run(init_op)\n","    STEPS = 5000\n","    for i in range(STEPS):\n","        start = (i*batch_size) % 128\n","        end = (i*batch_size) % 128 + batch_size\n","        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n","        if i % 1000 == 0:\n","            print(\"After %d training step(s), w1 is: \" % (i))\n","            print sess.run(w1), \"\\n\"\n","    print \"Final w1 is: \\n\", sess.run(w1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["After 0 training step(s), w1 is: \n","[[-0.81231821]\n"," [ 1.48359871]] \n","\n","After 1000 training step(s), w1 is: \n","[[ 0.18643527]\n"," [ 1.07393336]] \n","\n","After 2000 training step(s), w1 is: \n","[[ 0.95444274]\n"," [ 0.98088616]] \n","\n","After 3000 training step(s), w1 is: \n","[[ 0.95574027]\n"," [ 0.9806633 ]] \n","\n","After 4000 training step(s), w1 is: \n","[[ 0.95466018]\n"," [ 0.98135227]] \n","\n","Final w1 is: \n","[[ 0.95525807]\n"," [ 0.9813394 ]]\n"],"name":"stdout"}]},{"metadata":{"id":"OY9omsS0Krgo","colab_type":"text"},"cell_type":"markdown","source":["#### 6. 定义损失函数为MSE。"]},{"metadata":{"id":"TEQgqip8Krgp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"f0482fdb-4b2a-4096-de43-5125e12f1521"},"cell_type":"code","source":["loss = tf.losses.mean_squared_error(y, y_)\n","train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n","\n","with tf.Session() as sess:\n","    init_op = tf.global_variables_initializer()\n","    sess.run(init_op)\n","    STEPS = 5000\n","    for i in range(STEPS):\n","        start = (i*batch_size) % 128\n","        end = (i*batch_size) % 128 + batch_size\n","        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n","        if i % 1000 == 0:\n","            print(\"After %d training step(s), w1 is: \" % (i))\n","            print sess.run(w1), \"\\n\"\n","    print \"Final w1 is: \\n\", sess.run(w1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["After 0 training step(s), w1 is: \n","[[-0.81031823]\n"," [ 1.4855988 ]] \n","\n","After 1000 training step(s), w1 is: \n","[[-0.13337609]\n"," [ 1.81309223]] \n","\n","After 2000 training step(s), w1 is: \n","[[ 0.32190299]\n"," [ 1.52463484]] \n","\n","After 3000 training step(s), w1 is: \n","[[ 0.67850214]\n"," [ 1.25297272]] \n","\n","After 4000 training step(s), w1 is: \n","[[ 0.89473999]\n"," [ 1.08598232]] \n","\n","Final w1 is: \n","[[ 0.97437561]\n"," [ 1.0243336 ]]\n"],"name":"stdout"}]}]}